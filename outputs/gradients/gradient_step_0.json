{
  "step": 0,
  "lora_gradients": {
    "base_model.model.bert.encoder.layer.0.attention.self.query.lora_A.default.weight": 0.0,
    "base_model.model.bert.encoder.layer.0.attention.self.query.lora_B.default.weight": 0.009033203125,
    "base_model.model.bert.encoder.layer.0.attention.self.value.lora_A.default.weight": 0.0,
    "base_model.model.bert.encoder.layer.0.attention.self.value.lora_B.default.weight": 0.0233154296875,
    "base_model.model.bert.encoder.layer.1.attention.self.query.lora_A.default.weight": 0.0,
    "base_model.model.bert.encoder.layer.1.attention.self.query.lora_B.default.weight": 0.006744384765625,
    "base_model.model.bert.encoder.layer.1.attention.self.value.lora_A.default.weight": 0.0,
    "base_model.model.bert.encoder.layer.1.attention.self.value.lora_B.default.weight": 0.031982421875,
    "base_model.model.bert.encoder.layer.2.attention.self.query.lora_A.default.weight": 0.0,
    "base_model.model.bert.encoder.layer.2.attention.self.query.lora_B.default.weight": 0.005767822265625,
    "base_model.model.bert.encoder.layer.2.attention.self.value.lora_A.default.weight": 0.0,
    "base_model.model.bert.encoder.layer.2.attention.self.value.lora_B.default.weight": 0.028564453125,
    "base_model.model.bert.encoder.layer.3.attention.self.query.lora_A.default.weight": 0.0,
    "base_model.model.bert.encoder.layer.3.attention.self.query.lora_B.default.weight": 0.01226806640625,
    "base_model.model.bert.encoder.layer.3.attention.self.value.lora_A.default.weight": 0.0,
    "base_model.model.bert.encoder.layer.3.attention.self.value.lora_B.default.weight": 0.033203125,
    "base_model.model.bert.encoder.layer.4.attention.self.query.lora_A.default.weight": 0.0,
    "base_model.model.bert.encoder.layer.4.attention.self.query.lora_B.default.weight": 0.00830078125,
    "base_model.model.bert.encoder.layer.4.attention.self.value.lora_A.default.weight": 0.0,
    "base_model.model.bert.encoder.layer.4.attention.self.value.lora_B.default.weight": 0.025634765625,
    "base_model.model.bert.encoder.layer.5.attention.self.query.lora_A.default.weight": 0.0,
    "base_model.model.bert.encoder.layer.5.attention.self.query.lora_B.default.weight": 0.007354736328125,
    "base_model.model.bert.encoder.layer.5.attention.self.value.lora_A.default.weight": 0.0,
    "base_model.model.bert.encoder.layer.5.attention.self.value.lora_B.default.weight": 0.0252685546875,
    "base_model.model.bert.encoder.layer.6.attention.self.query.lora_A.default.weight": 0.0,
    "base_model.model.bert.encoder.layer.6.attention.self.query.lora_B.default.weight": 0.00848388671875,
    "base_model.model.bert.encoder.layer.6.attention.self.value.lora_A.default.weight": 0.0,
    "base_model.model.bert.encoder.layer.6.attention.self.value.lora_B.default.weight": 0.032470703125,
    "base_model.model.bert.encoder.layer.7.attention.self.query.lora_A.default.weight": 0.0,
    "base_model.model.bert.encoder.layer.7.attention.self.query.lora_B.default.weight": 0.00677490234375,
    "base_model.model.bert.encoder.layer.7.attention.self.value.lora_A.default.weight": 0.0,
    "base_model.model.bert.encoder.layer.7.attention.self.value.lora_B.default.weight": 0.0263671875,
    "base_model.model.bert.encoder.layer.8.attention.self.query.lora_A.default.weight": 0.0,
    "base_model.model.bert.encoder.layer.8.attention.self.query.lora_B.default.weight": 0.0123291015625,
    "base_model.model.bert.encoder.layer.8.attention.self.value.lora_A.default.weight": 0.0,
    "base_model.model.bert.encoder.layer.8.attention.self.value.lora_B.default.weight": 0.0294189453125,
    "base_model.model.bert.encoder.layer.9.attention.self.query.lora_A.default.weight": 0.0,
    "base_model.model.bert.encoder.layer.9.attention.self.query.lora_B.default.weight": 0.01239013671875,
    "base_model.model.bert.encoder.layer.9.attention.self.value.lora_A.default.weight": 0.0,
    "base_model.model.bert.encoder.layer.9.attention.self.value.lora_B.default.weight": 0.0225830078125,
    "base_model.model.bert.encoder.layer.10.attention.self.query.lora_A.default.weight": 0.0,
    "base_model.model.bert.encoder.layer.10.attention.self.query.lora_B.default.weight": 0.01519775390625,
    "base_model.model.bert.encoder.layer.10.attention.self.value.lora_A.default.weight": 0.0,
    "base_model.model.bert.encoder.layer.10.attention.self.value.lora_B.default.weight": 0.0242919921875,
    "base_model.model.bert.encoder.layer.11.attention.self.query.lora_A.default.weight": 0.0,
    "base_model.model.bert.encoder.layer.11.attention.self.query.lora_B.default.weight": 0.0091552734375,
    "base_model.model.bert.encoder.layer.11.attention.self.value.lora_A.default.weight": 0.0,
    "base_model.model.bert.encoder.layer.11.attention.self.value.lora_B.default.weight": 0.0169677734375
  },
  "base_gradients": {
    "base_model.model.classifier.modules_to_save.default.weight": 0.9921875,
    "base_model.model.classifier.modules_to_save.default.bias": 0.06591796875
  },
  "statistics": {
    "lora_mean": 0.009038925170898438,
    "lora_max": 0.033203125,
    "lora_min": 0.0,
    "base_mean": 0.529052734375,
    "base_max": 0.9921875
  }
}