{
  "step": 400,
  "lora_gradients": {
    "base_model.model.bert.encoder.layer.0.attention.self.query.lora_A.default.weight": 0.00299072265625,
    "base_model.model.bert.encoder.layer.0.attention.self.query.lora_B.default.weight": 0.008544921875,
    "base_model.model.bert.encoder.layer.0.attention.self.value.lora_A.default.weight": 0.0157470703125,
    "base_model.model.bert.encoder.layer.0.attention.self.value.lora_B.default.weight": 0.041748046875,
    "base_model.model.bert.encoder.layer.1.attention.self.query.lora_A.default.weight": 0.0021514892578125,
    "base_model.model.bert.encoder.layer.1.attention.self.query.lora_B.default.weight": 0.01080322265625,
    "base_model.model.bert.encoder.layer.1.attention.self.value.lora_A.default.weight": 0.007568359375,
    "base_model.model.bert.encoder.layer.1.attention.self.value.lora_B.default.weight": 0.0537109375,
    "base_model.model.bert.encoder.layer.2.attention.self.query.lora_A.default.weight": 0.0022125244140625,
    "base_model.model.bert.encoder.layer.2.attention.self.query.lora_B.default.weight": 0.0093994140625,
    "base_model.model.bert.encoder.layer.2.attention.self.value.lora_A.default.weight": 0.012939453125,
    "base_model.model.bert.encoder.layer.2.attention.self.value.lora_B.default.weight": 0.061767578125,
    "base_model.model.bert.encoder.layer.3.attention.self.query.lora_A.default.weight": 0.0021209716796875,
    "base_model.model.bert.encoder.layer.3.attention.self.query.lora_B.default.weight": 0.0115966796875,
    "base_model.model.bert.encoder.layer.3.attention.self.value.lora_A.default.weight": 0.01385498046875,
    "base_model.model.bert.encoder.layer.3.attention.self.value.lora_B.default.weight": 0.11279296875,
    "base_model.model.bert.encoder.layer.4.attention.self.query.lora_A.default.weight": 0.002410888671875,
    "base_model.model.bert.encoder.layer.4.attention.self.query.lora_B.default.weight": 0.0162353515625,
    "base_model.model.bert.encoder.layer.4.attention.self.value.lora_A.default.weight": 0.0203857421875,
    "base_model.model.bert.encoder.layer.4.attention.self.value.lora_B.default.weight": 0.1259765625,
    "base_model.model.bert.encoder.layer.5.attention.self.query.lora_A.default.weight": 0.004364013671875,
    "base_model.model.bert.encoder.layer.5.attention.self.query.lora_B.default.weight": 0.0220947265625,
    "base_model.model.bert.encoder.layer.5.attention.self.value.lora_A.default.weight": 0.016845703125,
    "base_model.model.bert.encoder.layer.5.attention.self.value.lora_B.default.weight": 0.1318359375,
    "base_model.model.bert.encoder.layer.6.attention.self.query.lora_A.default.weight": 0.003387451171875,
    "base_model.model.bert.encoder.layer.6.attention.self.query.lora_B.default.weight": 0.0194091796875,
    "base_model.model.bert.encoder.layer.6.attention.self.value.lora_A.default.weight": 0.03173828125,
    "base_model.model.bert.encoder.layer.6.attention.self.value.lora_B.default.weight": 0.177734375,
    "base_model.model.bert.encoder.layer.7.attention.self.query.lora_A.default.weight": 0.0020904541015625,
    "base_model.model.bert.encoder.layer.7.attention.self.query.lora_B.default.weight": 0.01251220703125,
    "base_model.model.bert.encoder.layer.7.attention.self.value.lora_A.default.weight": 0.033447265625,
    "base_model.model.bert.encoder.layer.7.attention.self.value.lora_B.default.weight": 0.1943359375,
    "base_model.model.bert.encoder.layer.8.attention.self.query.lora_A.default.weight": 0.00579833984375,
    "base_model.model.bert.encoder.layer.8.attention.self.query.lora_B.default.weight": 0.028564453125,
    "base_model.model.bert.encoder.layer.8.attention.self.value.lora_A.default.weight": 0.11279296875,
    "base_model.model.bert.encoder.layer.8.attention.self.value.lora_B.default.weight": 0.328125,
    "base_model.model.bert.encoder.layer.9.attention.self.query.lora_A.default.weight": 0.01409912109375,
    "base_model.model.bert.encoder.layer.9.attention.self.query.lora_B.default.weight": 0.03759765625,
    "base_model.model.bert.encoder.layer.9.attention.self.value.lora_A.default.weight": 0.1259765625,
    "base_model.model.bert.encoder.layer.9.attention.self.value.lora_B.default.weight": 0.2177734375,
    "base_model.model.bert.encoder.layer.10.attention.self.query.lora_A.default.weight": 0.0034027099609375,
    "base_model.model.bert.encoder.layer.10.attention.self.query.lora_B.default.weight": 0.04052734375,
    "base_model.model.bert.encoder.layer.10.attention.self.value.lora_A.default.weight": 0.3046875,
    "base_model.model.bert.encoder.layer.10.attention.self.value.lora_B.default.weight": 0.12890625,
    "base_model.model.bert.encoder.layer.11.attention.self.query.lora_A.default.weight": 0.0037078857421875,
    "base_model.model.bert.encoder.layer.11.attention.self.query.lora_B.default.weight": 0.0169677734375,
    "base_model.model.bert.encoder.layer.11.attention.self.value.lora_A.default.weight": 0.189453125,
    "base_model.model.bert.encoder.layer.11.attention.self.value.lora_B.default.weight": 0.0308837890625
  },
  "base_gradients": {
    "base_model.model.classifier.modules_to_save.default.weight": 0.7265625,
    "base_model.model.classifier.modules_to_save.default.bias": 0.06396484375
  },
  "statistics": {
    "lora_mean": 0.05779202779134115,
    "lora_max": 0.328125,
    "lora_min": 0.0020904541015625,
    "base_mean": 0.395263671875,
    "base_max": 0.7265625
  }
}